{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meta_learner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMTpBCmk3zOv"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mACUJCoO5gBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dda4682-a716-45a9-db88-90c0320185f0"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-SBz36GFBtk",
        "outputId": "72df61b5-d3cb-4a6c-803d-e70072ef974d"
      },
      "source": [
        "import datetime\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas\n",
        "import sklearn.metrics as metrics\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from numpy import asarray, hstack, vstack\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "import keras \n",
        "import tensorflow\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# step_feat = ['goals_conceded_shift','npg_shift','form','bonus_shift','bps_shift','clean_sheets_shift','assists_shift','total_points_shift_to_value','npg_shift_to_value','influence_shift_to_value','value','bps_shift_to_value','bonus_shift_to_value','influence_shift','yellow_cards_shift','goals_scored_shift','goals_scored_shift_to_value','minutes_shift','penalties_saved_shift','saves_shift','own_goals_shift','red_cards_shift','position_DEF','transfers_out','xGChain_shift','Player_Rank_No','total_points_shift_per_minute','bps_shift_per_minute','team_Spurs','team_Wolves','team_Chelsea','bonus_shift_per_minute','opponent_team_Brighton','xA_shift','Supporters','team_Newcastle','team_Man Utd','team_Everton','team_Brighton','opponent_team_West Ham','threat_shift','transfers_balance','position_GK']\n",
        "# get_step_data = FunctionTransformer(lambda x: x[step_feat], validate=False)\n",
        "\n",
        "def plot_results(true_value, predicted_value, title):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(true_value, predicted_value, c='crimson')\n",
        "    p1 = max(max(predicted_value), max(true_value))\n",
        "    p2 = min(min(predicted_value), min(true_value))\n",
        "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "    plt.xlabel('True Values', fontsize=15)\n",
        "    plt.ylabel('Predictions', fontsize=15)\n",
        "    plt.title(title)\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "def regression_results(y_true, y_pred, model_string):\n",
        "    print('# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>')\n",
        "    print(model_string)\n",
        "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
        "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
        "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
        "    r2 = metrics.r2_score(y_true, y_pred)\n",
        "    print('explained_variance: ', round(explained_variance, 4))\n",
        "    print('r2: ', round(r2, 4))\n",
        "    print('MAE: ', round(mean_absolute_error, 4))\n",
        "    print('MSE: ', round(mse, 4))\n",
        "    print('RMSE: ', round(np.sqrt(mse), 4))\n",
        "\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(500, activation= \"relu\",))\n",
        "    model.add(Dense(500, activation= \"relu\"))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_models():\n",
        "    models = list()\n",
        "    # models.append(('SW', Pipeline([('selector', get_step_data), ('LR', LinearRegression())])))   \n",
        "    # models.append(SVR(C=100, epsilon=0.01, kernel='rbf'))\n",
        "    # models.append(KNeighborsRegressor(n_neighbors=3))\n",
        "    # models.append(KerasRegressor(build_fn=baseline_model, epochs=50, verbose=False,validation_split=0.2))\n",
        "    models.append(LinearRegression())   \n",
        "    models.append(LinearRegression())   \n",
        "\n",
        "    return models\n",
        "\n",
        "def get_out_of_fold_predictions(X, y, models):\n",
        "    meta_X, meta_y = list(), list()\n",
        "    # define split of data\n",
        "    kfold = KFold(n_splits=5, shuffle=True)\n",
        "    # enumerate splits\n",
        "    for train_ix, test_ix in kfold.split(X):\n",
        "        fold_yhats = list()\n",
        "        # get data\n",
        "        train_X, test_X = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
        "        train_y, test_y = y.iloc[train_ix], y.iloc[test_ix]\n",
        "        meta_y.extend(test_y)\n",
        "        # fit and make predictions with each sub-model\n",
        "        for model in models:\n",
        "            print('Training', model.__class__.__name__) # TODO: GET FEAT\n",
        "            model.fit(train_X, train_y)  #\n",
        "            yhat = model.predict(test_X)  \n",
        "            fold_yhats.append(yhat.reshape(len(yhat), 1)) # store columns\n",
        "        meta_X.append(hstack(fold_yhats))\n",
        "    return vstack(meta_X), asarray(meta_y)\n",
        "\n",
        "def fit_base_models(X, y, models):\n",
        "    for model in models:\n",
        "        model.fit(X, y)\n",
        "    return models\n",
        "\n",
        "def fit_meta_model(X, y): # Meta learner\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "def evaluate_models(X, y, models, std_y):\n",
        "    for model in models:\n",
        "        yhat = np.round(std_y.inverse_transform(model.predict(X)))\n",
        "        y = np.round(std_y.inverse_transform(y))\n",
        "        mse = mean_squared_error(y, yhat)\n",
        "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
        "\n",
        "def super_learner_predictions(X, models, meta_model):\n",
        "    meta_X = list()\n",
        "    for model in models:\n",
        "        yhat = model.predict(X)\n",
        "        meta_X.append(yhat.reshape(len(yhat),1))\n",
        "    meta_X = hstack(meta_X)\n",
        "    # predict\n",
        "    return meta_model.predict(meta_X)\n",
        "\n",
        "def scale_datasets(df):\n",
        "  scaled_cols = []\n",
        "  for col in df.columns.drop('total_points'):\n",
        "    if df[col].nunique() > 2:\n",
        "      scaled_cols.append(col)\n",
        "  std_pred, std_resp = StandardScaler(), StandardScaler()\n",
        "  X_train, y_train = df.drop('total_points', axis=1), df['total_points'] \n",
        "  X_train[scaled_cols] = pd.DataFrame(std_pred.fit_transform(X_train[scaled_cols]), \n",
        "                                      columns=df[scaled_cols].columns,\n",
        "                                      index=X_train.index)\n",
        "  y_train = pd.DataFrame(std_resp.fit_transform(y_train.to_numpy().reshape(-1, 1)),\n",
        "                                                columns=['total_points'], index=y_train.index)\n",
        "  return X_train, y_train, std_resp\n",
        "\n",
        "def dont_scale_datasets(df):\n",
        "  X_train, y_train = df.drop('total_points', axis=1), df['total_points'] \n",
        "  return X_train, y_train\n",
        "\n",
        "def preprocess_data(df):\n",
        "  # Drop indexing features\n",
        "  idxrs = df[['player_name', 'kickoff_time', 'season', 'GW']]\n",
        "  df = df.drop(columns = ['player_name', 'kickoff_time', 'season', 'GW'])\n",
        "  # Binary encoding\n",
        "  for col in df.columns:\n",
        "    df[col] = df[col].replace({True:1, False:0})\n",
        "  # One hot encodings\n",
        "  ohe_cols = []\n",
        "  for col in df.select_dtypes(include='object').columns:\n",
        "      ohe_cols.append(col)\n",
        "  df = pd.get_dummies(df, columns=ohe_cols, prefix=ohe_cols)\n",
        "  df['kickoff_time'] = idxrs['kickoff_time']\n",
        "  df['GW'] = idxrs['GW']\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_training_data(GW, scale):\n",
        "    df = pd.read_csv('./drive/MyDrive/Data/engineered_us.csv')\n",
        "    df.drop(['team', 'opponent_team'], inplace = True, axis = 1)\n",
        "    df = preprocess_data(df)\n",
        "    min_date = df[(df['GW'] == GW) & (df['kickoff_time'] >= '2020-08-12')]['kickoff_time'].min() # The first date of the gameweek\n",
        "    max_date = df[(df['GW'] == GW) & (df['kickoff_time'] > '2020-08-12')]['kickoff_time'].max() # The last date of the gameweek\n",
        "    df_scl = df[df['kickoff_time'] <= max_date].copy() # Only includes up to gameweek \n",
        "    std_x, std_y = StandardScaler(), StandardScaler()\n",
        "    scaled_cols = []\n",
        "    if scale == True:\n",
        "      for col in df.columns.drop(['total_points', 'kickoff_time']):\n",
        "        if df[col].nunique() > 2:\n",
        "          scaled_cols.append(col)\n",
        "      df_scl[scaled_cols] = std_x.fit_transform(df_scl[scaled_cols])\n",
        "      df_scl['total_points'] = std_y.fit_transform(df_scl['total_points'].to_numpy().reshape(-1, 1))\n",
        "      df_train, df_test = df_scl[df_scl['kickoff_time'] < min_date], df_scl[df_scl['kickoff_time'] >= min_date] \n",
        "      X = df_train.drop(['total_points', 'kickoff_time', 'GW'], axis = 1)\n",
        "      y = df_train['total_points']\n",
        "      X_val = df_test.drop(['total_points', 'kickoff_time', 'GW'], axis = 1)\n",
        "      y_val = df_test['total_points']\n",
        "    else:\n",
        "      df_train, df_test = df_scl[df_scl['kickoff_time'] < min_date], df_scl[df_scl['kickoff_time'] >= min_date] \n",
        "      X = df_train.drop(['total_points', 'kickoff_time', 'GW'], axis = 1)\n",
        "      y = df_train['total_points']\n",
        "      X_val = df_test.drop(['total_points', 'kickoff_time', 'GW'], axis = 1)\n",
        "      y_val = df_test['total_points']\n",
        "    return X, X_val, y, y_val, std_x, std_y\n",
        "\n",
        "def write_grid_results(grid, file = 'results.txt'):\n",
        "  f = open(f'/content/drive/MyDrive/Parameters/{file}', 'w')\n",
        "  print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
        "  f.write(\"Best: %f using %s\\n\\n\" % (grid.best_score_, grid.best_params_))\n",
        "  means = grid.cv_results_['mean_test_score']\n",
        "  stds = grid.cv_results_['std_test_score']\n",
        "  params = grid.cv_results_['params'] \n",
        "  used = []\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "      f.write(\"%f (%f) with: %r\\n\\n\" % (mean, stdev, param))\n",
        "      used.append(param)\n",
        "  f.close()\n",
        "  X_train, X_test, y_train, y_test, std_x, std_y = get_training_data(GW = 1, scale = True)\n",
        "\n",
        "\n",
        "def get_stacked_mod(GW):\n",
        "    X, X_val, y, y_val, std_x, std_y = get_training_data(GW, scale = True)\n",
        "    print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)\n",
        "    models = get_models()\n",
        "    meta_X, meta_y = get_out_of_fold_predictions(X, y, models)\n",
        "    # return meta_X, meta_y\n",
        "    # print('Meta ', meta_X.shape, meta_y.shape)\n",
        "    models = fit_base_models(X, y, models)\n",
        "    meta_model = fit_meta_model(meta_X, meta_y)\n",
        "    evaluate_models(X_val, y_val, models, std_y)\n",
        "    yhat = super_learner_predictions(X_val, models, meta_model)\n",
        "    # # regression_results(np.round(std_y.inverse_transform(y_val)), np.round(std_y.inverse_transform(yhat)), 'Stacked')\n",
        "    # # plot_results(y_val, yhat, title = f'Testing Stacking for GW ')\n",
        "    print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(np.round(std_y.inverse_transform(y_val)), np.round(std_y.inverse_transform(yhat))))))\n",
        "    # # print(pd.DataFrame({'True': np.round(std_y.inverse_transform(y_val)), 'Predicted': np.round(std_y.inverse_transform(yhat))}))\n",
        "    # return np.round(std_y.inverse_transform(yhat)).flatten().tolist()\n",
        "\n",
        "get_stacked_mod(1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (10658, 58) (10658,) Test (220, 58) (220,)\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "Training LinearRegression\n",
            "LinearRegression: RMSE 3.184\n",
            "LinearRegression: RMSE 13.586\n",
            "Super Learner: RMSE 3.182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ouytBXL20Kwx",
        "outputId": "de7c0dde-e588-44d3-e6b7-54bee6139791"
      },
      "source": [
        "models = get_models()\n",
        "pd.DataFrame(x, columns = [model.__class__.__name__ for model in models])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LinearRegression</th>\n",
              "      <th>LinearRegression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.893799</td>\n",
              "      <td>-0.893799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.608154</td>\n",
              "      <td>-0.608154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.795898</td>\n",
              "      <td>-0.795898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.083740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040283</td>\n",
              "      <td>0.040283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10653</th>\n",
              "      <td>-0.015778</td>\n",
              "      <td>-0.015778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10654</th>\n",
              "      <td>0.121376</td>\n",
              "      <td>0.121376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655</th>\n",
              "      <td>0.203335</td>\n",
              "      <td>0.203335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10656</th>\n",
              "      <td>-0.026716</td>\n",
              "      <td>-0.026716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10657</th>\n",
              "      <td>0.088684</td>\n",
              "      <td>0.088684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10658 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       LinearRegression  LinearRegression\n",
              "0             -0.893799         -0.893799\n",
              "1             -0.608154         -0.608154\n",
              "2             -0.795898         -0.795898\n",
              "3              0.083740          0.083740\n",
              "4              0.040283          0.040283\n",
              "...                 ...               ...\n",
              "10653         -0.015778         -0.015778\n",
              "10654          0.121376          0.121376\n",
              "10655          0.203335          0.203335\n",
              "10656         -0.026716         -0.026716\n",
              "10657          0.088684          0.088684\n",
              "\n",
              "[10658 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}