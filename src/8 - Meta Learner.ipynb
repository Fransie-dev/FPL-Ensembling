{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_meta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjifzdvReydE"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mACUJCoO5gBG",
        "outputId": "3ee04595-ff43-4977-feb3-c90943f39a54"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iORFc02e01K",
        "outputId": "ef7488cc-aaad-4704-bba6-4a7c9b45f0a8"
      },
      "source": [
        "! pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.3-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "814PW_x0e1jU"
      },
      "source": [
        "Cat-Boost Meta-Learner "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKdSYC6_BCZh"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas\n",
        "import sklearn.metrics as metrics\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from numpy import asarray, hstack, vstack\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "import keras \n",
        "import tensorflow\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import catboost as cb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "pd.options.mode.chained_assignment = None  \n",
        "bwd_feat = pd.read_csv('./drive/MyDrive/BorutaShap/bwd_feat.csv')['Feat']\n",
        "bor_feat = pd.read_csv('./drive/MyDrive/BorutaShap/borutashap.csv')['feat']\n",
        "knn_feat = pd.read_csv('./drive/MyDrive/BorutaShap/knn_step.csv')['feat']\n",
        "step_feat = pd.read_csv('./drive/MyDrive/BorutaShap/step_feat.csv')['Feat']\n",
        "get_bwd_data = FunctionTransformer(lambda x: x[bwd_feat.values], validate=False)\n",
        "get_bor_data = FunctionTransformer(lambda x: x[bor_feat.values], validate=False)\n",
        "get_knn_data = FunctionTransformer(lambda x: x[knn_feat.values], validate=False)\n",
        "\n",
        "\n",
        "\n",
        "def gameweek_rmses(df):\n",
        "    results = pd.DataFrame(index = np.arange(1,39))\n",
        "    for name, model in get_models(cat_features=None):\n",
        "        RMSE = np.sqrt(mean_squared_error(df['total_points'], df[name]))\n",
        "        results[f'{name}'] = RMSE\n",
        "    results['Meta'] =  np.sqrt(mean_squared_error(df['total_points'], df['Meta']))\n",
        "    results.drop_duplicates(inplace = True)\n",
        "    results['Best'] = results.idxmin(axis=1)\n",
        "    results['BestRSME'] = results.min(axis=1)\n",
        "    return results.round(3)\n",
        "\n",
        "def split_dfs(df, GW, szn = 2020, idx = False):\n",
        "    X_test = df[(df['season'] == szn) & (df['GW'] == GW)]\n",
        "    y_test = X_test['total_points']\n",
        "    X_train = df[df['kickoff_time'] < X_test['kickoff_time'].min()]\n",
        "    y_train = X_train['total_points']\n",
        "    if idx == True:\n",
        "        idxrs_test = X_test[['player_name', 'kickoff_time', 'GW', 'season']]\n",
        "        X_test.drop(DROP_COLS, axis = 1, inplace = True), X_train.drop(DROP_COLS, axis = 1, inplace = True) \n",
        "        return X_train, X_test, y_train, y_test, idxrs_test\n",
        "    else:\n",
        "        # Removes kickoff time, gameweek, season and total points\n",
        "        X_test.drop(DROP_COLS, axis = 1, inplace = True), X_train.drop(DROP_COLS, axis = 1, inplace = True) \n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def get_training_data(GW, df, df_encoded, X_oof_train, std_x, std_y): \n",
        "    if GW == 1:\n",
        "        # Get, sort and round numerical precision..\n",
        "        df =  pd.read_csv('/content/drive/MyDrive/Data/rollbacked_us.csv').round(8).sort_values(by = ['season', 'GW', 'player_name', 'kickoff_time'])\n",
        "        # X_oof_train = pd.read_csv('./drive/MyDrive/Predictions/oof_predictions_10.csv').round(8)\n",
        "        X_oof_train = pd.read_csv('./drive/MyDrive/Predictions/unrounded_oof_predictions_10.csv').round(8)\n",
        "        df = df[df['season'] < 2021] # Predict for /21 \n",
        "        # Encode cats\n",
        "        df_encoded = encode_categoricals(df)\n",
        "        # Scale data\n",
        "        for data in [df_encoded, df]:\n",
        "            scaled_cols, error_cols, std_x, std_y = [], [], StandardScaler(), StandardScaler()\n",
        "            for col in data.select_dtypes(include = 'number').drop([col1 for col1 in DROP_COLS if col1 in data.select_dtypes(include = 'number').columns], axis = 1).columns:\n",
        "                if data[col].nunique() > 2:\n",
        "                    scaled_cols.append(col)\n",
        "                if data[col].min() < 1e-7:\n",
        "                    error_cols.append(col)\n",
        "            data[scaled_cols] = std_x.fit_transform(data[scaled_cols])\n",
        "            data['total_points'] = std_y.fit_transform(data['total_points'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "        X_oof_train[scaled_cols] = std_x.transform(X_oof_train[scaled_cols])\n",
        "        X_oof_train.drop(DROP_COLS, axis = 1, inplace = True)\n",
        "        for name, _ in get_models():\n",
        "            X_oof_train[name] = std_y.transform(X_oof_train[name].to_numpy().reshape(-1, 1))\n",
        "    else:\n",
        "        pass \n",
        "      \n",
        "  \n",
        "    # Construct data for CBoost base + get indexers\n",
        "    X_train, X_test, y_train, y_test, idxrs_test = split_dfs(df, GW, idx = True) \n",
        "\n",
        "    # Construct data for other base learners\n",
        "    X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = split_dfs(df_encoded, GW) # Does not contain player name\n",
        "\n",
        "    return X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, df, df_encoded, std_x, std_y, X_oof_train, idxrs_test\n",
        "\n",
        "def encode_categoricals(df):\n",
        "    # Any model that needs numerical preprocessing cannot use the name feature\n",
        "    encode_df = df.drop(columns = ['player_name'], axis = 1)\n",
        "    # Encode booleans\n",
        "    for col in encode_df.columns:\n",
        "      if pd.api.types.is_bool_dtype(encode_df[col]):\n",
        "        encode_df[col] = encode_df[col].replace({True:1, False:0})\n",
        "    # One hot encode \n",
        "    encode_df = pd.get_dummies(encode_df, columns=OHE_COLS, prefix=OHE_COLS)\n",
        "    # Ordinal encoding\n",
        "    mapping = {'Low': 0, 'Medium': 0.5, 'Hard':1}\n",
        "    encode_df['FDR'] = encode_df['FDR'].map(lambda x : mapping[x])\n",
        "    return encode_df\n",
        "\n",
        "def get_models(cat_features = None):\n",
        "\n",
        "    models = list()\n",
        "    # Linear Regression\n",
        "    models.append(('LR', Pipeline([('selector', get_bwd_data), ('LR', LinearRegression())]))) # Done\n",
        "    # CatBoost\n",
        "    models.append(('CBoost', Pipeline([('CBoost', cb.CatBoostRegressor(loss_function='RMSE', cat_features = cat_features,\n",
        "                                                                       task_type=TASK_TYPE, logging_level='Silent', depth = 6,\n",
        "                                                                       l2_leaf_reg = 1, learning_rate = 0.03,\n",
        "                                                                       bagging_temperature = 0.1, iterations = ITERATIONS))]))) \n",
        "    # SVR\n",
        "    models.append(('SVR', Pipeline([('selector', get_bor_data), ('SVR', SVR(C=6, cache_size=200, coef0=0.0, degree=3, epsilon=0.6, gamma=0.005, \n",
        "                                                                            kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))]))) \n",
        "    # KNN\n",
        "    models.append(('KNN', Pipeline([('selector', get_knn_data), ('KNN', KNeighborsRegressor(algorithm='kd_tree', leaf_size=1, metric='manhattan',\n",
        "                                                                                            metric_params=None, n_jobs=8, n_neighbors=86, p=2,\n",
        "                                                                                            weights='distance'))]))) \n",
        "    # Neural Network\n",
        "    models.append(('MLP', Pipeline([('selector', get_bor_data), ('MLP', MLPRegressor(activation='identity', alpha=1e-05, batch_size=16, beta_1=0.9,\n",
        "                                                                                     beta_2=0.999, early_stopping=True, epsilon=1e-07,\n",
        "                                                                                     hidden_layer_sizes=(64, 128), learning_rate='constant',\n",
        "                                                                                     learning_rate_init=0.0001, max_fun=15000, max_iter=50,\n",
        "                                                                                     momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "                                                                                     power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
        "                                                                                     tol=1e-08, validation_fraction=0.1, verbose=False,\n",
        "                                                                                     warm_start=False))])))  \n",
        "    return models\n",
        "\n",
        "\n",
        "\n",
        "def get_out_of_fold_predictions(GW, X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, models):\n",
        "    meta_X, meta_y, y_index, fold_yhats = list(), list(), list(), list()\n",
        "    # Store folds\n",
        "    meta_y.extend(y_test)\n",
        "    y_index = y_test.index\n",
        "    # Encode categorical features for base learners' \n",
        "    # Get validation predictions of all base learners\n",
        "    for name, model in models:\n",
        "        start = time.time()\n",
        "        if name in ['CBoost']:\n",
        "            X_train_base, X_test_base = X_train, X_test\n",
        "            if EARLY_STOPPING:\n",
        "                model.fit(X_train_base, y_train, CBoost__early_stopping_rounds = 100, CBoost__eval_set = [(X_test_base, y_test)])\n",
        "            else:\n",
        "                 model.fit(X_train_base, y_train)\n",
        "        else:\n",
        "            X_train_base, X_test_base = X_train_encoded, X_test_encoded\n",
        "            model.fit(X_train_base, y_train)  \n",
        "\n",
        "        # Get base learners' predictions\n",
        "        yhat = model.predict(X_test_base)  \n",
        "        fold_yhats.append(yhat.reshape(len(yhat), 1)) \n",
        "        # Profile model\n",
        "        if VERBOSE:\n",
        "            print(f'{GW}: {name}: {round(time.time()-start,3)} seconds') \n",
        "    # Store base learner predictions as columns\n",
        "    meta_X.append(hstack(fold_yhats)) \n",
        "    # Scaled out-of-fold predictions of base learners\n",
        "    y_oof_true = pd.DataFrame(asarray(meta_y), index=y_index)\n",
        "    X_oof_preds = pd.DataFrame(vstack(meta_X), columns = [name for name, _ in models], index=y_index)\n",
        "    return X_oof_preds, y_oof_true, y_index \n",
        "    \n",
        "\n",
        "def construct_oof_data(GW, X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, X_oof_train):\n",
        "    if not PROPAGATE:\n",
        "      X_train.drop(['team', 'opponent_team', 'player_name'], axis = 1, inplace = True)\n",
        "      X_test.drop(['team', 'opponent_team', 'player_name'], axis = 1, inplace = True)\n",
        "    # Categorical features in level-0 training set\n",
        "    cat_features_train = np.where(X_train.dtypes == 'object')[0] \n",
        "    # Base learners \n",
        "    models = get_models(cat_features_train) \n",
        "    # Get base learners OOF preds\n",
        "    X_oof_preds, y_oof_true, y_index = get_out_of_fold_predictions(GW, X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, models) \n",
        "    # Construct propagated level-1 test set\n",
        "    X_oof_test = pd.merge(X_oof_preds, X_test, left_index=True, right_index=True) \n",
        "    X_oof_test.to_csv(f'/content/drive/MyDrive/Predictions/{GW}_oof.csv', index = False)\n",
        "    # Categorical features in level-1 testing set\n",
        "    # Concatenate new data to training data\n",
        "    if GW > 1:\n",
        "        X_oof_train = pd.concat([X_oof_train, pd.read_csv(f'/content/drive/MyDrive/Predictions/{GW - 1}_oof.csv')])\n",
        "    X_oof_train = X_oof_train[X_oof_test.columns]\n",
        "    return X_oof_test, y_oof_true, cat_features_train,  models, X_oof_train\n",
        "\n",
        "\n",
        "def fit_meta_model(GW, X_oof_train, y_oof_train, X_oof_test, y_oof_true): \n",
        "    start = time.time()\n",
        "    model =  cb.CatBoostRegressor(cat_features =  np.where(X_oof_train.dtypes == 'object')[0], task_type=TASK_TYPE,\n",
        "                                  depth = 8, \n",
        "                                  iterations = ITERATIONS,\n",
        "                                  l2_leaf_reg = 1,\n",
        "                                  learning_rate = 0.03, \n",
        "                                  logging_level = 'Silent') # Test: Can early stopping improve performance?\n",
        "    if EARLY_STOPPING:\n",
        "        model.fit(X_oof_train, y_oof_train, early_stopping_rounds = 100, eval_set = [(X_oof_test, y_oof_true)])\n",
        "    else:\n",
        "        model.fit(X_oof_train, y_oof_train)\n",
        "    print(f'{GW}: Meta: {round(time.time()-start,3)} seconds') \n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # For all gameweeks\n",
        "    for GW in list(range(1,39)):\n",
        "        if not VERBOSE:\n",
        "            print(GW)\n",
        "        if GW == 1:\n",
        "            results, df, df_encoded, std_x, std_y, X_oof_train = [], [], [], [], [], []\n",
        "        else:\n",
        "            pass\n",
        "        # Level-0 training + testing sets\n",
        "        X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, df, df_encoded, std_x, std_y, X_oof_train, idxrs_test = get_training_data(GW, df, df_encoded, X_oof_train, std_x, std_y)\n",
        "        # Construct level-1 training + testing sets\n",
        "        X_oof_test, y_oof_true, cat_features_train,  models, X_oof_train = construct_oof_data(GW, X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, X_oof_train)\n",
        "        # Fit meta-learner on level-1 training set\n",
        "        meta_model = fit_meta_model(GW, X_oof_train, y_train, X_oof_test, y_oof_true) \n",
        "        # Predict using meta_model\n",
        "        meta_preds = meta_model.predict(X_oof_test)\n",
        "        # Print weekly RMSE\n",
        "        if VERBOSE:\n",
        "            print(f'{GW} : Meta-learner : RMSE = {sqrt(mean_squared_error(np.round(std_y.inverse_transform(y_test)), np.round(std_y.inverse_transform(meta_preds))))}')\n",
        "            for name, _ in models:\n",
        "                print(f'{GW} : {name} : RMSE = {sqrt(mean_squared_error(np.round(std_y.inverse_transform(y_test)), np.round(std_y.inverse_transform(X_oof_test[name]))))}')\n",
        "        # Should response be rounded\n",
        "        if ROUND:\n",
        "            for name, _ in models:\n",
        "                idxrs_test[name] = np.round(std_y.inverse_transform(X_oof_test[name]))\n",
        "            idxrs_test['Meta'] = np.round(std_y.inverse_transform(meta_preds))\n",
        "        else: \n",
        "            for name, _ in models:\n",
        "                idxrs_test[name] = std_y.inverse_transform(X_oof_test[name])\n",
        "            idxrs_test['Meta'] = std_y.inverse_transform(meta_preds)\n",
        "        # Save weekly results\n",
        "        results.append(idxrs_test)\n",
        "    # Concatenate all predictions\n",
        "    df_preds = pd.concat(results).reset_index(drop=True)    \n",
        "    # Save the results with the original player name\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Data/collected_us.csv')[['player_name', 'position', 'team', 'value', 'kickoff_time', 'total_points']]\n",
        "    df = df[df['kickoff_time'] > '2020-08-12'] # Predicted for the /21 season\n",
        "    df_preds = pd.merge(df_preds, df, on = ['player_name', 'kickoff_time'])\n",
        "    df_preds.to_csv('/content/drive/MyDrive/Predictions/new_meta_early_stop_no_rounding.csv', index = False)\n",
        "    # Use the previous gameweek testing results as early stopping criterion\n",
        "\n",
        "\n",
        "# Test parameters\n",
        "N_SPLITS = 10\n",
        "TASK_TYPE = 'CPU' # GPU is giving inconsistent results\n",
        "ITERATIONS = 1000 \n",
        "VERBOSE = True\n",
        "PROPAGATE = True # Player name, team and opponent team features\n",
        "ROUND = False\n",
        "EARLY_STOPPING = True\n",
        "OHE_COLS =  ['team', 'position', 'opponent_team', 'position_location', 'premium_players']\n",
        "DROP_COLS = ['kickoff_time', 'total_points', 'GW', 'season']\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlpAtxRRfv4s"
      },
      "source": [
        "CatBoost Meta Learner with propagation (> 80 min)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF0XSgiPfyos",
        "outputId": "35cdc8dd-4a9b-4029-d8c7-122e3cb308d3"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_cboost_vanilla.csv')\n",
        "#  LR &   CBoost &      SVR &      KNN &      MLP &     Meta &                                               Best &  BestRSME \\\\\n",
        "\n",
        "# Total &  741 &       38 &  106.521 &  105.146 &  107.434 &  107.053 &  106.357 &  108.011 &  CBoostLRKNNSVRCBoostCBoostCBoostCBoostMLPLRLRC... &   104.638 \\\\\n",
        "# Total &  741 &       38 &  106.954 &  105.731 &  108.202 &  107.678 &  106.838 &  107.520 &  CBoostLRKNNMLPMLPCBoostCBoostCBoostCBoostCBoos... &   104.943 \\\\\n",
        "# Total &  741 &       38 &  106.954 &  107.917 &  108.202 &  107.678 &  106.838 &  108.348 &  CBoostLRKNNMLPMLPMLPCBoostKNNMLPLRLRSVRLRLRLRK... &   105.404 \\\\\n",
        "\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_early_stop_no_rounding.csv')\n",
        "results = df.groupby('GW').apply(gameweek_rmses).reset_index()\n",
        "print(results.append(results.sum().rename('Total')).to_latex())\n",
        "print(\"Total season performance\")\n",
        "for name in ['LR', 'KNN', 'MLP', 'SVR', 'CBoost', 'Meta']:\n",
        "    print(f'{name} : {np.sqrt(mean_squared_error(df.total_points, df[name]))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrrrrrlr}\n",
            "\\toprule\n",
            "{} &   GW &  level\\_1 &       LR &   CBoost &      SVR &      KNN &      MLP &     Meta &                                               Best &  BestRSME \\\\\n",
            "\\midrule\n",
            "0     &    1 &        1 &    3.356 &    3.122 &    3.172 &    3.312 &    3.169 &    3.362 &                                             CBoost &     3.122 \\\\\n",
            "1     &    2 &        1 &    3.505 &    3.633 &    3.653 &    3.611 &    3.554 &    3.838 &                                                 LR &     3.505 \\\\\n",
            "2     &    3 &        1 &    2.970 &    3.098 &    2.939 &    2.902 &    2.939 &    2.926 &                                                KNN &     2.902 \\\\\n",
            "3     &    4 &        1 &    3.727 &    3.758 &    3.632 &    3.698 &    3.618 &    3.799 &                                                MLP &     3.618 \\\\\n",
            "4     &    5 &        1 &    2.635 &    2.772 &    2.779 &    2.653 &    2.628 &    2.786 &                                                MLP &     2.628 \\\\\n",
            "5     &    6 &        1 &    2.586 &    2.744 &    2.653 &    2.605 &    2.566 &    2.621 &                                                MLP &     2.566 \\\\\n",
            "6     &    7 &        1 &    2.910 &    2.873 &    3.019 &    2.989 &    2.971 &    3.050 &                                             CBoost &     2.873 \\\\\n",
            "7     &    8 &        1 &    2.627 &    2.672 &    2.714 &    2.625 &    2.638 &    2.735 &                                                KNN &     2.625 \\\\\n",
            "8     &    9 &        1 &    2.512 &    2.547 &    2.532 &    2.536 &    2.494 &    2.545 &                                                MLP &     2.494 \\\\\n",
            "9     &   10 &        1 &    2.969 &    3.039 &    2.974 &    3.010 &    2.986 &    3.024 &                                                 LR &     2.969 \\\\\n",
            "10    &   11 &        1 &    2.669 &    2.733 &    2.766 &    2.747 &    2.676 &    2.792 &                                                 LR &     2.669 \\\\\n",
            "11    &   12 &        1 &    2.703 &    2.649 &    2.631 &    2.637 &    2.634 &    2.677 &                                                SVR &     2.631 \\\\\n",
            "12    &   13 &        1 &    2.625 &    2.688 &    2.704 &    2.660 &    2.660 &    2.681 &                                                 LR &     2.625 \\\\\n",
            "13    &   14 &        1 &    3.045 &    3.163 &    3.162 &    3.088 &    3.102 &    3.206 &                                                 LR &     3.045 \\\\\n",
            "14    &   15 &        1 &    2.661 &    2.819 &    2.690 &    2.692 &    2.691 &    2.687 &                                                 LR &     2.661 \\\\\n",
            "15    &   16 &        1 &    2.563 &    2.555 &    2.545 &    2.508 &    2.630 &    2.572 &                                                KNN &     2.508 \\\\\n",
            "16    &   17 &        1 &    2.847 &    2.958 &    2.934 &    2.891 &    2.858 &    2.829 &                                               Meta &     2.829 \\\\\n",
            "17    &   18 &        1 &    2.374 &    2.466 &    2.348 &    2.389 &    2.386 &    2.363 &                                                SVR &     2.348 \\\\\n",
            "18    &   19 &        1 &    2.772 &    2.648 &    2.737 &    2.769 &    2.736 &    2.757 &                                             CBoost &     2.648 \\\\\n",
            "19    &   20 &        1 &    2.858 &    2.828 &    2.828 &    2.911 &    2.884 &    2.847 &                                             CBoost &     2.828 \\\\\n",
            "20    &   21 &        1 &    2.782 &    2.796 &    2.789 &    2.769 &    2.724 &    2.834 &                                                MLP &     2.724 \\\\\n",
            "21    &   22 &        1 &    2.934 &    3.015 &    3.008 &    2.926 &    2.882 &    2.987 &                                                MLP &     2.882 \\\\\n",
            "22    &   23 &        1 &    2.740 &    2.771 &    2.884 &    2.855 &    2.735 &    2.765 &                                                MLP &     2.735 \\\\\n",
            "23    &   24 &        1 &    2.908 &    2.913 &    2.960 &    2.967 &    2.906 &    2.912 &                                                MLP &     2.906 \\\\\n",
            "24    &   25 &        1 &    2.582 &    2.596 &    2.533 &    2.541 &    2.550 &    2.589 &                                                SVR &     2.533 \\\\\n",
            "25    &   26 &        1 &    2.657 &    2.723 &    2.683 &    2.704 &    2.685 &    2.670 &                                                 LR &     2.657 \\\\\n",
            "26    &   27 &        1 &    2.913 &    2.815 &    2.991 &    2.932 &    2.926 &    2.954 &                                             CBoost &     2.815 \\\\\n",
            "27    &   28 &        1 &    2.517 &    2.485 &    2.547 &    2.525 &    2.503 &    2.467 &                                               Meta &     2.467 \\\\\n",
            "28    &   29 &        1 &    2.627 &    2.615 &    2.754 &    2.742 &    2.578 &    2.680 &                                                MLP &     2.578 \\\\\n",
            "29    &   30 &        1 &    3.068 &    3.139 &    3.019 &    3.070 &    3.062 &    3.077 &                                                SVR &     3.019 \\\\\n",
            "30    &   31 &        1 &    2.988 &    2.958 &    2.946 &    2.944 &    3.002 &    2.901 &                                               Meta &     2.901 \\\\\n",
            "31    &   32 &        1 &    2.527 &    2.546 &    2.632 &    2.624 &    2.605 &    2.587 &                                                 LR &     2.527 \\\\\n",
            "32    &   33 &        1 &    2.761 &    2.737 &    2.687 &    2.641 &    2.747 &    2.638 &                                               Meta &     2.638 \\\\\n",
            "33    &   34 &        1 &    2.663 &    2.622 &    2.807 &    2.757 &    2.696 &    2.642 &                                             CBoost &     2.622 \\\\\n",
            "34    &   35 &        1 &    2.664 &    2.663 &    2.730 &    2.679 &    2.656 &    2.729 &                                                MLP &     2.656 \\\\\n",
            "35    &   36 &        1 &    3.089 &    3.108 &    3.091 &    3.099 &    3.091 &    3.127 &                                                 LR &     3.089 \\\\\n",
            "36    &   37 &        1 &    2.699 &    2.725 &    2.685 &    2.640 &    2.690 &    2.655 &                                                KNN &     2.640 \\\\\n",
            "37    &   38 &        1 &    2.921 &    2.925 &    3.044 &    3.030 &    2.980 &    3.037 &                                                 LR &     2.921 \\\\\n",
            "Total &  741 &       38 &  106.954 &  107.917 &  108.202 &  107.678 &  106.838 &  108.348 &  CBoostLRKNNMLPMLPMLPCBoostKNNMLPLRLRSVRLRLRLRK... &   105.404 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n",
            "Total season performance\n",
            "LR : 2.8282238284757155\n",
            "KNN : 2.847404857517841\n",
            "MLP : 2.825376144757988\n",
            "SVR : 2.8603496959856756\n",
            "CBoost : 2.853372486584416\n",
            "Meta : 2.868663200471324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq163RQBe9GH"
      },
      "source": [
        "CatBoost Meta Learner with propagation and early stopping (~ 20 min)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pdC_8uYvdzB",
        "outputId": "cddbcf55-2266-4783-dc59-925e13ef0201"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_cboost_with_prop_and_early_stop.csv')\n",
        "results = df.groupby('GW').apply(gameweek_rmses).reset_index()\n",
        "print(results.append(results.sum().rename('Total')).to_latex())\n",
        "print(\"Total season performance\")\n",
        "for name in ['LR', 'KNN', 'MLP', 'SVR', 'CBoost', 'Meta']:\n",
        "    print(f'{name} : {np.sqrt(mean_squared_error(df.total_points, df[name]))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrrrrrlr}\n",
            "\\toprule\n",
            "{} &   GW &  level\\_1 &       LR &   CBoost &      SVR &      KNN &      MLP &     Meta &                                               Best &  BestRSME \\\\\n",
            "\\midrule\n",
            "0     &    1 &        1 &    3.356 &    3.056 &    3.172 &    3.312 &    3.169 &    3.321 &                                             CBoost &     3.056 \\\\\n",
            "1     &    2 &        1 &    3.505 &    3.563 &    3.653 &    3.611 &    3.554 &    3.760 &                                                 LR &     3.505 \\\\\n",
            "2     &    3 &        1 &    2.970 &    2.928 &    2.939 &    2.902 &    2.939 &    2.906 &                                                KNN &     2.902 \\\\\n",
            "3     &    4 &        1 &    3.727 &    3.691 &    3.632 &    3.698 &    3.618 &    3.745 &                                                MLP &     3.618 \\\\\n",
            "4     &    5 &        1 &    2.635 &    2.639 &    2.779 &    2.653 &    2.628 &    2.762 &                                                MLP &     2.628 \\\\\n",
            "5     &    6 &        1 &    2.586 &    2.538 &    2.653 &    2.605 &    2.566 &    2.580 &                                             CBoost &     2.538 \\\\\n",
            "6     &    7 &        1 &    2.910 &    2.823 &    3.019 &    2.989 &    2.971 &    3.023 &                                             CBoost &     2.823 \\\\\n",
            "7     &    8 &        1 &    2.627 &    2.606 &    2.714 &    2.625 &    2.638 &    2.708 &                                             CBoost &     2.606 \\\\\n",
            "8     &    9 &        1 &    2.512 &    2.472 &    2.532 &    2.536 &    2.494 &    2.480 &                                             CBoost &     2.472 \\\\\n",
            "9     &   10 &        1 &    2.969 &    2.955 &    2.974 &    3.010 &    2.986 &    3.004 &                                             CBoost &     2.955 \\\\\n",
            "10    &   11 &        1 &    2.669 &    2.702 &    2.766 &    2.747 &    2.676 &    2.767 &                                                 LR &     2.669 \\\\\n",
            "11    &   12 &        1 &    2.703 &    2.596 &    2.631 &    2.637 &    2.634 &    2.649 &                                             CBoost &     2.596 \\\\\n",
            "12    &   13 &        1 &    2.625 &    2.598 &    2.704 &    2.660 &    2.660 &    2.642 &                                             CBoost &     2.598 \\\\\n",
            "13    &   14 &        1 &    3.045 &    3.145 &    3.162 &    3.088 &    3.102 &    3.206 &                                                 LR &     3.045 \\\\\n",
            "14    &   15 &        1 &    2.661 &    2.685 &    2.690 &    2.692 &    2.691 &    2.687 &                                                 LR &     2.661 \\\\\n",
            "15    &   16 &        1 &    2.563 &    2.574 &    2.545 &    2.508 &    2.630 &    2.612 &                                                KNN &     2.508 \\\\\n",
            "16    &   17 &        1 &    2.847 &    2.854 &    2.934 &    2.891 &    2.858 &    2.815 &                                               Meta &     2.815 \\\\\n",
            "17    &   18 &        1 &    2.374 &    2.332 &    2.348 &    2.389 &    2.386 &    2.328 &                                               Meta &     2.328 \\\\\n",
            "18    &   19 &        1 &    2.772 &    2.660 &    2.737 &    2.769 &    2.736 &    2.724 &                                             CBoost &     2.660 \\\\\n",
            "19    &   20 &        1 &    2.858 &    2.824 &    2.828 &    2.911 &    2.884 &    2.848 &                                             CBoost &     2.824 \\\\\n",
            "20    &   21 &        1 &    2.782 &    2.787 &    2.789 &    2.769 &    2.724 &    2.783 &                                                MLP &     2.724 \\\\\n",
            "21    &   22 &        1 &    2.934 &    2.957 &    3.008 &    2.926 &    2.882 &    2.964 &                                                MLP &     2.882 \\\\\n",
            "22    &   23 &        1 &    2.740 &    2.745 &    2.884 &    2.855 &    2.735 &    2.754 &                                                MLP &     2.735 \\\\\n",
            "23    &   24 &        1 &    2.908 &    2.877 &    2.960 &    2.967 &    2.906 &    2.955 &                                             CBoost &     2.877 \\\\\n",
            "24    &   25 &        1 &    2.582 &    2.544 &    2.533 &    2.541 &    2.550 &    2.544 &                                                SVR &     2.533 \\\\\n",
            "25    &   26 &        1 &    2.657 &    2.637 &    2.683 &    2.704 &    2.685 &    2.651 &                                             CBoost &     2.637 \\\\\n",
            "26    &   27 &        1 &    2.913 &    2.816 &    2.991 &    2.932 &    2.926 &    2.948 &                                             CBoost &     2.816 \\\\\n",
            "27    &   28 &        1 &    2.517 &    2.474 &    2.547 &    2.525 &    2.503 &    2.468 &                                               Meta &     2.468 \\\\\n",
            "28    &   29 &        1 &    2.627 &    2.553 &    2.754 &    2.742 &    2.578 &    2.654 &                                             CBoost &     2.553 \\\\\n",
            "29    &   30 &        1 &    3.068 &    3.056 &    3.019 &    3.070 &    3.062 &    3.070 &                                                SVR &     3.019 \\\\\n",
            "30    &   31 &        1 &    2.988 &    2.931 &    2.946 &    2.944 &    3.002 &    2.860 &                                               Meta &     2.860 \\\\\n",
            "31    &   32 &        1 &    2.527 &    2.551 &    2.632 &    2.624 &    2.605 &    2.592 &                                                 LR &     2.527 \\\\\n",
            "32    &   33 &        1 &    2.761 &    2.649 &    2.687 &    2.641 &    2.747 &    2.659 &                                                KNN &     2.641 \\\\\n",
            "33    &   34 &        1 &    2.663 &    2.647 &    2.807 &    2.757 &    2.696 &    2.660 &                                             CBoost &     2.647 \\\\\n",
            "34    &   35 &        1 &    2.664 &    2.641 &    2.730 &    2.679 &    2.656 &    2.661 &                                             CBoost &     2.641 \\\\\n",
            "35    &   36 &        1 &    3.089 &    3.039 &    3.091 &    3.099 &    3.091 &    3.094 &                                             CBoost &     3.039 \\\\\n",
            "36    &   37 &        1 &    2.699 &    2.657 &    2.685 &    2.640 &    2.690 &    2.616 &                                               Meta &     2.616 \\\\\n",
            "37    &   38 &        1 &    2.921 &    2.929 &    3.044 &    3.030 &    2.980 &    3.020 &                                                 LR &     2.921 \\\\\n",
            "Total &  741 &       38 &  106.954 &  105.731 &  108.202 &  107.678 &  106.838 &  107.520 &  CBoostLRKNNMLPMLPCBoostCBoostCBoostCBoostCBoos... &   104.943 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n",
            "Total season performance\n",
            "LR : 2.8282238284757155\n",
            "KNN : 2.847404857517841\n",
            "MLP : 2.825376144757988\n",
            "SVR : 2.8603496959856756\n",
            "CBoost : 2.7974935732340076\n",
            "Meta : 2.8456710623192096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j256JxkIfBNw"
      },
      "source": [
        "CatBoost Meta-Learner with prop (wiuth the player name, team, and opponent team features removed) and with early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqUuDO91mNM",
        "outputId": "b9855410-c11b-4dbb-d547-e99b2874485a"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_cboost_without_prop_with_early_stopping.csv')\n",
        "results = df.groupby('GW').apply(gameweek_rmses).reset_index()\n",
        "print(results.append(results.sum().rename('Total')).to_latex())\n",
        "print(\"Total season performance\")\n",
        "for name in ['LR', 'KNN', 'MLP', 'SVR', 'CBoost', 'Meta']:\n",
        "    print(f'{name} : {np.sqrt(mean_squared_error(df.total_points, df[name]))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrrrrrlr}\n",
            "\\toprule\n",
            "{} &   GW &  level\\_1 &       LR &   CBoost &      SVR &      KNN &      MLP &     Meta &                                               Best &  BestRSME \\\\\n",
            "\\midrule\n",
            "0     &    1 &        1 &    3.356 &    3.107 &    3.172 &    3.312 &    3.169 &    3.321 &                                             CBoost &     3.107 \\\\\n",
            "1     &    2 &        1 &    3.505 &    3.490 &    3.653 &    3.611 &    3.554 &    3.751 &                                             CBoost &     3.490 \\\\\n",
            "2     &    3 &        1 &    2.970 &    2.888 &    2.939 &    2.902 &    2.939 &    2.929 &                                             CBoost &     2.888 \\\\\n",
            "3     &    4 &        1 &    3.727 &    3.692 &    3.632 &    3.698 &    3.618 &    3.768 &                                                MLP &     3.618 \\\\\n",
            "4     &    5 &        1 &    2.635 &    2.626 &    2.779 &    2.653 &    2.628 &    2.763 &                                             CBoost &     2.626 \\\\\n",
            "5     &    6 &        1 &    2.586 &    2.513 &    2.653 &    2.605 &    2.566 &    2.565 &                                             CBoost &     2.513 \\\\\n",
            "6     &    7 &        1 &    2.910 &    3.007 &    3.019 &    2.989 &    2.971 &    3.025 &                                                 LR &     2.910 \\\\\n",
            "7     &    8 &        1 &    2.627 &    2.658 &    2.714 &    2.625 &    2.638 &    2.750 &                                                KNN &     2.625 \\\\\n",
            "8     &    9 &        1 &    2.512 &    2.488 &    2.532 &    2.536 &    2.494 &    2.465 &                                               Meta &     2.465 \\\\\n",
            "9     &   10 &        1 &    2.969 &    2.889 &    2.974 &    3.010 &    2.986 &    2.987 &                                             CBoost &     2.889 \\\\\n",
            "10    &   11 &        1 &    2.669 &    2.725 &    2.766 &    2.747 &    2.676 &    2.834 &                                                 LR &     2.669 \\\\\n",
            "11    &   12 &        1 &    2.703 &    2.649 &    2.631 &    2.637 &    2.634 &    2.664 &                                                SVR &     2.631 \\\\\n",
            "12    &   13 &        1 &    2.625 &    2.620 &    2.704 &    2.660 &    2.660 &    2.636 &                                             CBoost &     2.620 \\\\\n",
            "13    &   14 &        1 &    3.045 &    3.122 &    3.162 &    3.088 &    3.102 &    3.176 &                                                 LR &     3.045 \\\\\n",
            "14    &   15 &        1 &    2.661 &    2.642 &    2.690 &    2.692 &    2.691 &    2.655 &                                             CBoost &     2.642 \\\\\n",
            "15    &   16 &        1 &    2.563 &    2.531 &    2.545 &    2.508 &    2.630 &    2.589 &                                                KNN &     2.508 \\\\\n",
            "16    &   17 &        1 &    2.847 &    2.905 &    2.934 &    2.891 &    2.858 &    2.849 &                                                 LR &     2.847 \\\\\n",
            "17    &   18 &        1 &    2.374 &    2.287 &    2.348 &    2.389 &    2.386 &    2.327 &                                             CBoost &     2.287 \\\\\n",
            "18    &   19 &        1 &    2.772 &    2.714 &    2.737 &    2.769 &    2.736 &    2.745 &                                             CBoost &     2.714 \\\\\n",
            "19    &   20 &        1 &    2.858 &    2.825 &    2.828 &    2.911 &    2.884 &    2.822 &                                               Meta &     2.822 \\\\\n",
            "20    &   21 &        1 &    2.782 &    2.763 &    2.789 &    2.769 &    2.724 &    2.771 &                                                MLP &     2.724 \\\\\n",
            "21    &   22 &        1 &    2.934 &    2.914 &    3.008 &    2.926 &    2.882 &    2.993 &                                                MLP &     2.882 \\\\\n",
            "22    &   23 &        1 &    2.740 &    2.725 &    2.884 &    2.855 &    2.735 &    2.798 &                                             CBoost &     2.725 \\\\\n",
            "23    &   24 &        1 &    2.908 &    2.855 &    2.960 &    2.967 &    2.906 &    2.929 &                                             CBoost &     2.855 \\\\\n",
            "24    &   25 &        1 &    2.582 &    2.516 &    2.533 &    2.541 &    2.550 &    2.562 &                                             CBoost &     2.516 \\\\\n",
            "25    &   26 &        1 &    2.657 &    2.625 &    2.683 &    2.704 &    2.685 &    2.661 &                                             CBoost &     2.625 \\\\\n",
            "26    &   27 &        1 &    2.913 &    2.863 &    2.991 &    2.932 &    2.926 &    2.971 &                                             CBoost &     2.863 \\\\\n",
            "27    &   28 &        1 &    2.517 &    2.512 &    2.547 &    2.525 &    2.503 &    2.512 &                                                MLP &     2.503 \\\\\n",
            "28    &   29 &        1 &    2.627 &    2.630 &    2.754 &    2.742 &    2.578 &    2.646 &                                                MLP &     2.578 \\\\\n",
            "29    &   30 &        1 &    3.068 &    3.056 &    3.019 &    3.070 &    3.062 &    3.052 &                                                SVR &     3.019 \\\\\n",
            "30    &   31 &        1 &    2.988 &    2.928 &    2.946 &    2.944 &    3.002 &    2.930 &                                             CBoost &     2.928 \\\\\n",
            "31    &   32 &        1 &    2.527 &    2.551 &    2.632 &    2.624 &    2.605 &    2.575 &                                                 LR &     2.527 \\\\\n",
            "32    &   33 &        1 &    2.761 &    2.646 &    2.687 &    2.641 &    2.747 &    2.626 &                                               Meta &     2.626 \\\\\n",
            "33    &   34 &        1 &    2.663 &    2.625 &    2.807 &    2.757 &    2.696 &    2.684 &                                             CBoost &     2.625 \\\\\n",
            "34    &   35 &        1 &    2.664 &    2.654 &    2.730 &    2.679 &    2.656 &    2.691 &                                             CBoost &     2.654 \\\\\n",
            "35    &   36 &        1 &    3.089 &    3.030 &    3.091 &    3.099 &    3.091 &    3.069 &                                             CBoost &     3.030 \\\\\n",
            "36    &   37 &        1 &    2.699 &    2.619 &    2.685 &    2.640 &    2.690 &    2.608 &                                               Meta &     2.608 \\\\\n",
            "37    &   38 &        1 &    2.921 &    2.964 &    3.044 &    3.030 &    2.980 &    3.055 &                                                 LR &     2.921 \\\\\n",
            "Total &  741 &       38 &  106.954 &  105.854 &  108.202 &  107.678 &  106.838 &  107.754 &  CBoostCBoostCBoostMLPCBoostCBoostLRKNNMetaCBoo... &   105.125 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n",
            "Total season performance\n",
            "LR : 2.8282238284757155\n",
            "KNN : 2.847404857517841\n",
            "MLP : 2.825376144757988\n",
            "SVR : 2.8603496959856756\n",
            "CBoost : 2.800164277472615\n",
            "Meta : 2.852784683499139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIS_OFbbhYcr"
      },
      "source": [
        "Other learners-performance as meta-learners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpWblOPlEq7c"
      },
      "source": [
        "def get_meta_models(cat_features = None):\n",
        "\n",
        "    models = list()\n",
        "    # Linear Regression\n",
        "    models.append(('LR', Pipeline([('LR', LinearRegression())]))) \n",
        "    # CatBoost\n",
        "    models.append(('CBoost', Pipeline([('CBoost', cb.CatBoostRegressor(loss_function='RMSE', cat_features = cat_features,\n",
        "                                                                       task_type=TASK_TYPE, logging_level='Silent', depth = 2,\n",
        "                                                                       l2_leaf_reg = 3, learning_rate = 0.03,\n",
        "                                                                       bagging_temperature = 0.1, iterations = ITERATIONS))]))) \n",
        "    # SVR\n",
        "    models.append(('SVR', Pipeline([('SVR', SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.6, gamma=0.005,\n",
        "                                               kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])))  \n",
        "    \n",
        "    # KNN\n",
        "    models.append(('KNN', Pipeline([('KNN', KNeighborsRegressor(algorithm='kd_tree', leaf_size=10, metric='euclidean',\n",
        "                                                                metric_params=None, n_jobs=8, n_neighbors=300, p=2,\n",
        "                                                                weights='uniform'))]))) \n",
        "    # Neural Network\n",
        "    models.append(('MLP', Pipeline([('MLP', MLPRegressor(activation='relu', alpha=0, batch_size=16, beta_1=0.9,\n",
        "                                                         beta_2=0.999, early_stopping=True, epsilon=1e-07,\n",
        "                                                         hidden_layer_sizes=(128, 256), learning_rate='constant',\n",
        "                                                         learning_rate_init=0.0001, max_fun=15000, max_iter=20,\n",
        "                                                         momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "                                                         power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
        "                                                         tol=1e-08, validation_fraction=0.1, verbose=False,\n",
        "                                                         warm_start=False))])))  \n",
        "    return models\n",
        "\n",
        "def meta_preds(GW, X_oof_train, y_oof_train, X_oof_test, y_oof_test): \n",
        "    preds, fold_yhats = list(), list()\n",
        "    for name, model in get_meta_models():\n",
        "        start = time.time()\n",
        "        model.fit(X_oof_train, y_oof_train)\n",
        "        yhat = model.predict(X_oof_test)  \n",
        "        fold_yhats.append(yhat.reshape(len(yhat), 1)) \n",
        "        print(f'{GW}: Meta: {round(time.time()-start,3)} seconds') \n",
        "    preds.append(hstack(fold_yhats)) \n",
        "    preds = pd.DataFrame(vstack(preds), columns = [name for name, _ in get_meta_models()])\n",
        "    return preds\n",
        "\n",
        "def quick_level_1(GW):  \n",
        "    # Separate training and testing\n",
        "    df_train = pd.read_csv('./drive/MyDrive/Predictions/oof_predictions_10.csv')\n",
        "    df_preds = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_cboost_vanilla.csv')\n",
        "    std_x, std_y = StandardScaler(), StandardScaler()\n",
        "    df_concat_train = df_preds[df_preds['GW'] < GW]\n",
        "    df_test = df_preds[df_preds['GW'] == GW]  \n",
        "    # Predictors\n",
        "    X_oof_train  = std_x.fit_transform(pd.concat([df_train[[name for name, _ in get_meta_models()]], \n",
        "                                                  df_concat_train[[name for name, _ in get_meta_models()]]]))\n",
        "    X_oof_test  = std_x.transform(df_test[[name for name, _ in get_meta_models()]])\n",
        "    \n",
        "    # Response\n",
        "    y_oof_train = std_y.fit_transform(pd.concat([df_train['total_points'], \n",
        "                                                 df_concat_train['total_points']]).to_numpy().reshape(-1, 1))\n",
        "    y_oof_test = std_y.fit_transform(df_test['total_points'].to_numpy().reshape(-1, 1))\n",
        "    # Keep track of players and gameweeks\n",
        "    test_idx = df_test[['player_name', 'kickoff_time', 'GW', 'season']]\n",
        "    return X_oof_train, y_oof_train, X_oof_test, y_oof_test, test_idx, std_y\n",
        "\n",
        "def main():\n",
        "    # For all gameweeks\n",
        "    results = []\n",
        "    for GW in list(range(1,39)):\n",
        "        # Get level-1 data set\n",
        "        X_oof_train, y_oof_train, X_oof_test, y_oof_test, idxrs_test, std_y = quick_level_1(GW)\n",
        "        # Get three models predictions\n",
        "        meta_predictions = meta_preds(GW, X_oof_train, y_oof_train, X_oof_test, y_oof_test)\n",
        "        # Save weekly results\n",
        "        for name, _ in get_meta_models():\n",
        "            idxrs_test[name] = np.round(std_y.inverse_transform(meta_predictions[name].to_numpy().reshape(-1, 1)))\n",
        "        # Indexers + results\n",
        "        idxrs_test['total_points'] = np.round(std_y.inverse_transform(y_oof_test))\n",
        "        results.append(idxrs_test)\n",
        "    # Concat all preds\n",
        "    df_preds = pd.concat(results).reset_index(drop=True)    \n",
        "    df_preds.to_csv('/content/drive/MyDrive/Predictions/other_metas.csv', index = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiA5WG2ENtlI"
      },
      "source": [
        "Simple weighted average of base and meta-learners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1k0L_Lv8VP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a25ca9c-d918-458f-d8d2-a4ae289c2eed"
      },
      "source": [
        "def gameweek_rmses(df):\n",
        "    results = pd.DataFrame(index = np.arange(1,39))\n",
        "    for name, model in get_meta_models(cat_features=None):\n",
        "        RMSE = np.sqrt(mean_squared_error(df['total_points'], df[name]))\n",
        "        results[f'{name}'] = RMSE\n",
        "    results['Avg. Base'] =  np.sqrt(mean_squared_error(df['total_points'], df['avg_base_preds']))\n",
        "    results['Avg. Meta'] =  np.sqrt(mean_squared_error(df['total_points'], df['avg_meta_preds']))\n",
        "    results.drop_duplicates(inplace = True)\n",
        "    results['Best'] = results.idxmin(axis=1)\n",
        "    results['BestRSME'] = results.min(axis=1)\n",
        "    return results.round(3)\n",
        "\n",
        "\n",
        "df_base = pd.read_csv('/content/drive/MyDrive/Predictions/new_meta_cboost_vanilla.csv')\n",
        "df_base['avg_base_preds'] = 0\n",
        "for name, model in get_models(cat_features=None):\n",
        "      df_base['avg_base_preds'] += df_base[name]/5\n",
        "\n",
        "\n",
        "df_preds = pd.read_csv('/content/drive/MyDrive/Predictions/other_metas.csv')\n",
        "df_preds['avg_meta_preds'] = 0\n",
        "for name, model in get_meta_models(cat_features=None):\n",
        "      df_preds['avg_meta_preds'] += df_preds[name]/5\n",
        "\n",
        "df_preds['avg_meta_preds'] = np.round(df_preds['avg_meta_preds'])\n",
        "df_preds['avg_base_preds'] = np.round(df_base['avg_base_preds'])\n",
        "\n",
        "results = df_preds.groupby('GW').apply(gameweek_rmses).reset_index()\n",
        "print(results.append(results.sum().rename('Total')).to_latex())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrrrrrrlr}\n",
            "\\toprule\n",
            "{} &   GW &  level\\_1 &       LR &   CBoost &      SVR &      KNN &      MLP &  Average Base &  Average Meta &                                               Best &  BestRSME \\\\\n",
            "\\midrule\n",
            "0     &    1 &        1 &    3.111 &    3.059 &    3.130 &    3.112 &    3.106 &         3.124 &         3.078 &                                             CBoost &     3.059 \\\\\n",
            "1     &    2 &        1 &    3.592 &    3.591 &    3.642 &    3.572 &    3.628 &         3.562 &         3.572 &                                       Average Base &     3.562 \\\\\n",
            "2     &    3 &        1 &    3.063 &    3.040 &    3.024 &    3.011 &    3.057 &         2.930 &         3.049 &                                       Average Base &     2.930 \\\\\n",
            "3     &    4 &        1 &    3.776 &    3.740 &    3.772 &    3.719 &    3.832 &         3.660 &         3.727 &                                       Average Base &     3.660 \\\\\n",
            "4     &    5 &        1 &    2.684 &    2.698 &    2.773 &    2.685 &    2.716 &         2.671 &         2.705 &                                       Average Base &     2.671 \\\\\n",
            "5     &    6 &        1 &    2.664 &    2.639 &    2.626 &    2.684 &    2.649 &         2.590 &         2.634 &                                       Average Base &     2.590 \\\\\n",
            "6     &    7 &        1 &    2.883 &    2.868 &    2.913 &    2.871 &    2.870 &         2.908 &         2.872 &                                             CBoost &     2.868 \\\\\n",
            "7     &    8 &        1 &    2.622 &    2.648 &    2.686 &    2.612 &    2.605 &         2.622 &         2.630 &                                                MLP &     2.605 \\\\\n",
            "8     &    9 &        1 &    2.505 &    2.496 &    2.536 &    2.527 &    2.510 &         2.498 &         2.495 &                                       Average Meta &     2.495 \\\\\n",
            "9     &   10 &        1 &    3.020 &    3.012 &    3.033 &    3.025 &    3.043 &         2.957 &         3.014 &                                       Average Base &     2.957 \\\\\n",
            "10    &   11 &        1 &    2.685 &    2.671 &    2.821 &    2.722 &    2.668 &         2.710 &         2.705 &                                                MLP &     2.668 \\\\\n",
            "11    &   12 &        1 &    2.613 &    2.627 &    2.623 &    2.647 &    2.653 &         2.626 &         2.623 &                                                 LR &     2.613 \\\\\n",
            "12    &   13 &        1 &    2.665 &    2.624 &    2.639 &    2.635 &    2.672 &         2.667 &         2.630 &                                             CBoost &     2.624 \\\\\n",
            "13    &   14 &        1 &    3.124 &    3.092 &    3.147 &    3.083 &    3.083 &         3.083 &         3.090 &                                                KNN &     3.083 \\\\\n",
            "14    &   15 &        1 &    2.729 &    2.732 &    2.708 &    2.707 &    2.715 &         2.687 &         2.721 &                                       Average Base &     2.687 \\\\\n",
            "15    &   16 &        1 &    2.520 &    2.572 &    2.512 &    2.513 &    2.535 &         2.530 &         2.537 &                                                SVR &     2.512 \\\\\n",
            "16    &   17 &        1 &    2.880 &    2.859 &    2.933 &    2.898 &    2.919 &         2.886 &         2.858 &                                       Average Meta &     2.858 \\\\\n",
            "17    &   18 &        1 &    2.368 &    2.380 &    2.310 &    2.315 &    2.353 &         2.357 &         2.340 &                                                SVR &     2.310 \\\\\n",
            "18    &   19 &        1 &    2.718 &    2.731 &    2.709 &    2.692 &    2.699 &         2.732 &         2.699 &                                                KNN &     2.692 \\\\\n",
            "19    &   20 &        1 &    2.821 &    2.830 &    2.853 &    2.821 &    2.848 &         2.822 &         2.830 &                                                 LR &     2.821 \\\\\n",
            "20    &   21 &        1 &    2.741 &    2.741 &    2.773 &    2.718 &    2.745 &         2.764 &         2.726 &                                                KNN &     2.718 \\\\\n",
            "21    &   22 &        1 &    2.934 &    2.945 &    2.999 &    2.968 &    2.966 &         2.911 &         2.964 &                                       Average Base &     2.911 \\\\\n",
            "22    &   23 &        1 &    2.770 &    2.768 &    2.837 &    2.754 &    2.757 &         2.818 &         2.778 &                                                KNN &     2.754 \\\\\n",
            "23    &   24 &        1 &    2.900 &    2.900 &    2.959 &    2.886 &    2.912 &         2.910 &         2.906 &                                                KNN &     2.886 \\\\\n",
            "24    &   25 &        1 &    2.578 &    2.583 &    2.556 &    2.559 &    2.580 &         2.546 &         2.580 &                                       Average Base &     2.546 \\\\\n",
            "25    &   26 &        1 &    2.663 &    2.676 &    2.650 &    2.667 &    2.678 &         2.649 &         2.671 &                                       Average Base &     2.649 \\\\\n",
            "26    &   27 &        1 &    2.880 &    2.902 &    2.921 &    2.893 &    2.877 &         2.908 &         2.880 &                                                MLP &     2.877 \\\\\n",
            "27    &   28 &        1 &    2.517 &    2.483 &    2.543 &    2.485 &    2.526 &         2.510 &         2.519 &                                             CBoost &     2.483 \\\\\n",
            "28    &   29 &        1 &    2.629 &    2.620 &    2.680 &    2.625 &    2.659 &         2.665 &         2.608 &                                       Average Meta &     2.608 \\\\\n",
            "29    &   30 &        1 &    3.087 &    3.100 &    3.055 &    3.110 &    3.127 &         3.053 &         3.100 &                                       Average Base &     3.053 \\\\\n",
            "30    &   31 &        1 &    2.963 &    2.951 &    2.948 &    2.979 &    2.959 &         2.955 &         2.936 &                                       Average Meta &     2.936 \\\\\n",
            "31    &   32 &        1 &    2.525 &    2.541 &    2.579 &    2.540 &    2.535 &         2.566 &         2.518 &                                       Average Meta &     2.518 \\\\\n",
            "32    &   33 &        1 &    2.715 &    2.699 &    2.670 &    2.709 &    2.734 &         2.700 &         2.737 &                                                SVR &     2.670 \\\\\n",
            "33    &   34 &        1 &    2.596 &    2.636 &    2.760 &    2.622 &    2.627 &         2.668 &         2.607 &                                                 LR &     2.596 \\\\\n",
            "34    &   35 &        1 &    2.638 &    2.627 &    2.701 &    2.651 &    2.626 &         2.655 &         2.612 &                                       Average Meta &     2.612 \\\\\n",
            "35    &   36 &        1 &    3.062 &    3.095 &    3.087 &    3.145 &    3.103 &         3.109 &         3.088 &                                                 LR &     3.062 \\\\\n",
            "36    &   37 &        1 &    2.690 &    2.713 &    2.677 &    2.691 &    2.713 &         2.656 &         2.704 &                                       Average Base &     2.656 \\\\\n",
            "37    &   38 &        1 &    2.904 &    2.897 &    3.008 &    2.931 &    2.899 &         2.955 &         2.901 &                                             CBoost &     2.897 \\\\\n",
            "Total &  741 &       38 &  106.835 &  106.786 &  107.793 &  106.784 &  107.184 &       106.620 &       106.644 &  CBoostAverage BaseAverage BaseAverage BaseAver... &   105.697 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7LxL3cmkCP_"
      },
      "source": [
        "Remove full stadium matches and test on 2021/22"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKSGj0rqIy1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d64c3a-1be3-40ee-e5ca-a6b37af4c581"
      },
      "source": [
        "df = pd.read_csv('./drive/MyDrive/Data/rollbacked_us_testing.csv')\n",
        "df = df[df['kickoff_time'] > '2020-04-01']\n",
        "df.groupby(['season'])['GW'].value_counts()\n",
        "# df[df['season'] == 2021]['kickoff_time'].min()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "season  GW\n",
              "2019    30    362\n",
              "        38    304\n",
              "        33    300\n",
              "        31    299\n",
              "        35    299\n",
              "        36    297\n",
              "        32    296\n",
              "        37    292\n",
              "        34    290\n",
              "2020    26    466\n",
              "        35    417\n",
              "        19    413\n",
              "        24    334\n",
              "        25    304\n",
              "        27    302\n",
              "        30    284\n",
              "        38    281\n",
              "        10    279\n",
              "        7     277\n",
              "        20    277\n",
              "        22    277\n",
              "        31    277\n",
              "        32    275\n",
              "        2     274\n",
              "        3     274\n",
              "        4     274\n",
              "        14    274\n",
              "        15    274\n",
              "        23    274\n",
              "        37    274\n",
              "        5     273\n",
              "        6     273\n",
              "        21    272\n",
              "        28    272\n",
              "        9     270\n",
              "        12    270\n",
              "        13    270\n",
              "        8     268\n",
              "        34    247\n",
              "        11    246\n",
              "        17    245\n",
              "        1     220\n",
              "        16    217\n",
              "        33    217\n",
              "        36    214\n",
              "        18    164\n",
              "        29    110\n",
              "2021    5     281\n",
              "        1     280\n",
              "        6     275\n",
              "        2     273\n",
              "        4     273\n",
              "        3     270\n",
              "        7     269\n",
              "Name: GW, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rcIjDo5a0F"
      },
      "source": [
        "def construct_level_1_training(X, y, models):\n",
        "    meta_X, meta_y, y_index = list(), list(), list()\n",
        "    kfold = KFold(n_splits=N_SPLITS, shuffle=True)\n",
        "    for k, (train_ix, test_ix) in enumerate(kfold.split(X)):\n",
        "        fold_yhats = list()\n",
        "        train_X, test_X = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
        "        encoded_train_X, encoded_test_X = encode_categoricals(train_X), encode_categoricals(test_X)\n",
        "        train_y, test_y = y.iloc[train_ix], y.iloc[test_ix]\n",
        "        meta_y.extend(test_y)\n",
        "        y_index.extend(test_ix)\n",
        "        start = time.time()\n",
        "         # Out of fold predictions  \n",
        "        for name, model in models:\n",
        "            X_train = train_X if name in ['CBoost'] else encoded_train_X\n",
        "            X_test = test_X if name in ['CBoost'] else encoded_test_X\n",
        "            model.fit(X_train, train_y)  \n",
        "            yhat = model.predict(X_test)  \n",
        "            fold_yhats.append(yhat.reshape(len(yhat), 1)) \n",
        "         # Model predictions as columns\n",
        "        meta_X.append(hstack(fold_yhats))\n",
        "        print(f'Fold {k+1}: {round(time.time()-start,3)} seconds') \n",
        "    # Note, not rounded or unscaled\n",
        "    meta_X = pd.DataFrame(vstack(meta_X), columns = [name for name, _ in get_models()], index=y_index)\n",
        "    X_oof_train = pd.merge(meta_X, X, left_index=True, right_index=True) \n",
        "    return X_oof_train\n",
        "\n",
        "\n",
        "def get_models(cat_features = None):\n",
        "\n",
        "    models = list()\n",
        "    # Linear Regression\n",
        "    models.append(('LR', Pipeline([('selector', get_bwd_data), ('LR', LinearRegression())]))) # Done\n",
        "    # CatBoost\n",
        "    models.append(('CBoost', Pipeline([('CBoost', cb.CatBoostRegressor(loss_function='RMSE', cat_features = cat_features,\n",
        "                                                                       task_type=TASK_TYPE, logging_level='Silent', depth = 6,\n",
        "                                                                       l2_leaf_reg = 1, learning_rate = 0.03,\n",
        "                                                                       bagging_temperature = 0.1, iterations = ITERATIONS))]))) \n",
        "    # SVR\n",
        "    models.append(('SVR', Pipeline([('selector', get_bor_data), ('SVR', SVR(C=6, cache_size=200, coef0=0.0, degree=3, epsilon=0.6, gamma=0.005, \n",
        "                                                                            kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))]))) \n",
        "    # KNN\n",
        "    models.append(('KNN', Pipeline([('selector', get_knn_data), ('KNN', KNeighborsRegressor(algorithm='kd_tree', leaf_size=1, metric='manhattan',\n",
        "                                                                                            metric_params=None, n_jobs=8, n_neighbors=86, p=2,\n",
        "                                                                                            weights='distance'))]))) \n",
        "    # Neural Network\n",
        "    models.append(('MLP', Pipeline([('selector', get_bor_data), ('MLP', MLPRegressor(activation='identity', alpha=1e-05, batch_size=16, beta_1=0.9,\n",
        "                                                                                     beta_2=0.999, early_stopping=True, epsilon=1e-07,\n",
        "                                                                                     hidden_layer_sizes=(64, 128), learning_rate='constant',\n",
        "                                                                                     learning_rate_init=0.0001, max_fun=15000, max_iter=50,\n",
        "                                                                                     momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "                                                                                     power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
        "                                                                                     tol=1e-08, validation_fraction=0.1, verbose=False,\n",
        "                                                                                     warm_start=False))])))  \n",
        "    return models\n",
        "\n",
        "\n",
        "\n",
        "def get_empty_stadium_training_data(GW, df, df_encoded, X_oof_train, std_x, std_y): \n",
        "    if GW == 1:\n",
        "        # Get, sort and round numerical precision..\n",
        "        df = pd.read_csv('./drive/MyDrive/Data/rollbacked_us_testing.csv').round(8).sort_values(by = ['season', 'GW', 'player_name', 'kickoff_time'])\n",
        "        df = df[df['kickoff_time'] > '2020-04-01'] # Empty stadiums\n",
        "        df.reset_index(inplace = True, drop = True)\n",
        "        # Encode cats\n",
        "        df_encoded = encode_categoricals(df)\n",
        "        # Scale data\n",
        "        for data in [df_encoded, df]:\n",
        "            scaled_cols, error_cols, std_x, std_y = [], [], StandardScaler(), StandardScaler()\n",
        "            for col in data.select_dtypes(include = 'number').drop([col1 for col1 in DROP_COLS if col1 in data.select_dtypes(include = 'number').columns], axis = 1).columns:\n",
        "                if data[col].nunique() > 2:\n",
        "                    scaled_cols.append(col)\n",
        "                if data[col].min() < 1e-7:\n",
        "                    error_cols.append(col)\n",
        "            data[scaled_cols] = std_x.fit_transform(data[scaled_cols])\n",
        "            data['total_points'] = std_y.fit_transform(data['total_points'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "        # Create a fresh OOF training set for the /22 season\n",
        "        X, _, y, _ = split_dfs(df, GW, szn = 2021) \n",
        "        X_oof_train = construct_level_1_training(X, y, models = get_models(cat_features = np.where(X.dtypes == 'object')[0]))\n",
        "        X_oof_train.to_csv('/content/drive/MyDrive/Predictions/out_of_fold_21.csv', index = False)\n",
        "        # X_oof_train =  pd.read_csv('/content/drive/MyDrive/Predictions/out_of_fold_21.csv').round(8).sort_values(by = ['season', 'GW', 'player_name', 'kickoff_time'])\n",
        "    else:\n",
        "        pass \n",
        "\n",
        "  \n",
        "    # Construct data for CBoost base + get indexers\n",
        "    X_train, X_test, y_train, y_test, idxrs_test = split_dfs(df, GW, idx = True, szn = 2021) \n",
        "\n",
        "    # Construct data for other base learners\n",
        "    X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = split_dfs(df_encoded, GW, szn = 2021) # Does not contain player name\n",
        "    \n",
        "    return X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, df, df_encoded, std_x, std_y, X_oof_train, idxrs_test\n",
        "\n",
        "def main():\n",
        "    # For all gameweeks\n",
        "    for GW in list(range(1,8)): # Predict for first seven gameweeks\n",
        "        if not VERBOSE:\n",
        "            print(GW)\n",
        "        if GW == 1:\n",
        "            results, df, df_encoded, std_x, std_y, X_oof_train = [], [], [], [], [], []\n",
        "        else:\n",
        "            pass\n",
        "        # Level-0 training + testing sets\n",
        "        X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, df, df_encoded, std_x, std_y, X_oof_train, idxrs_test = get_empty_stadium_training_data(GW, df, df_encoded, X_oof_train, std_x, std_y)\n",
        "        # Construct level-1 training + testing sets\n",
        "        X_oof_test, y_oof_true, cat_features_train,  models, X_oof_train = construct_oof_data(GW, X_train, X_test, X_train_encoded, X_test_encoded, y_train, y_test, X_oof_train)\n",
        "        # Fit meta-learner on level-1 training set\n",
        "        meta_model = fit_meta_model(GW, X_oof_train, y_train, X_oof_test, y_oof_true) \n",
        "        # Predict using meta_model\n",
        "        meta_preds = meta_model.predict(X_oof_test)\n",
        "        # Print weekly RMSE\n",
        "        if VERBOSE:\n",
        "            print(f'{GW} : Meta-learner : RMSE = {sqrt(mean_squared_error(np.round(std_y.inverse_transform(y_test)), np.round(std_y.inverse_transform(meta_preds))))}')\n",
        "            for name, _ in models:\n",
        "                print(f'{GW} : {name} : RMSE = {sqrt(mean_squared_error(np.round(std_y.inverse_transform(y_test)), np.round(std_y.inverse_transform(X_oof_test[name]))))}')\n",
        "        # Should response be rounded\n",
        "        if ROUND:\n",
        "            for name, _ in models:\n",
        "                idxrs_test[name] = np.round(std_y.inverse_transform(X_oof_test[name]))\n",
        "            idxrs_test['Meta'] = np.round(std_y.inverse_transform(meta_preds))\n",
        "        else: \n",
        "            for name, _ in models:\n",
        "                idxrs_test[name] = std_y.inverse_transform(X_oof_test[name])\n",
        "            idxrs_test['Meta'] = std_y.inverse_transform(meta_preds)\n",
        "        # Save weekly results\n",
        "        results.append(idxrs_test)\n",
        "    # Concatenate all predictions\n",
        "    df_preds = pd.concat(results).reset_index(drop=True)    \n",
        "    # Save the results with the original player name\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Data/collected_us_updated.csv')[['player_name', 'position', 'team', 'value', 'kickoff_time', 'total_points']]\n",
        "    df = df[df['kickoff_time'] > '2021-08-01'] # Predicted for the /22 season\n",
        "    df_preds = pd.merge(df_preds, df, on = ['player_name', 'kickoff_time'])\n",
        "    df_preds.to_csv('/content/drive/MyDrive/Predictions/empty_stadium_performance.csv', index = False)\n",
        "    # Use the previous gameweek testing results as early stopping criterion\n",
        "\n",
        "# Test parameters\n",
        "N_SPLITS = 10\n",
        "TASK_TYPE = 'CPU' # GPU is giving inconsistent results\n",
        "ITERATIONS = 1000 \n",
        "VERBOSE = True\n",
        "PROPAGATE = True # Player name, team and opponent team features\n",
        "ROUND = True\n",
        "EARLY_STOPPING = True\n",
        "OHE_COLS =  ['team', 'position', 'opponent_team', 'position_location', 'premium_players']\n",
        "DROP_COLS = ['kickoff_time', 'total_points', 'GW', 'season']\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Zp96lN5a7H"
      },
      "source": [
        "def gameweek_rmses(df):\n",
        "    results = pd.DataFrame(index = np.arange(1,8))\n",
        "    for name, model in get_models(cat_features=None):\n",
        "        RMSE = np.sqrt(mean_squared_error(df['total_points'], df[name]))\n",
        "        results[f'{name}'] = RMSE\n",
        "    results['Meta'] =  np.sqrt(mean_squared_error(df['total_points'], df['Meta']))\n",
        "    results.drop_duplicates(inplace = True)\n",
        "    results['Best Learner'] = results.idxmin(axis=1)\n",
        "    results['Best RMsE'] = results.min(axis=1)\n",
        "    return results.round(3)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Predictions/empty_stadium_performance.csv')\n",
        "results = df.groupby('GW').apply(gameweek_rmses).reset_index()\n",
        "print(results.append(results.sum().rename('Total')).to_latex())\n",
        "print(\"Total season performance\")\n",
        "for name in ['LR', 'KNN', 'MLP', 'SVR', 'CBoost', 'Meta']:\n",
        "    print(f'{name} : {np.sqrt(mean_squared_error(df.total_points, df[name]))}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}